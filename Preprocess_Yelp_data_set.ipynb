{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Yelp dataset\n",
    "## Preprocess the business.json and merge it with review.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_json_path = '/Users/zhiyuwang/Desktop/Desktop/tmp/yelp_dataset/business.json'\n",
    "review_json_path = '/Users/zhiyuwang/Desktop/Desktop/tmp/yelp_dataset/review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b=pd.read_json(business_json_path, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean the business.json file**\n",
    "* Include only current opened restaurants\n",
    "* we only want to focus on the restaurants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1= open, 0 = closed\n",
    "df_b = df_b[df_b['is_open']==1]\n",
    "\n",
    "# Only focus on restaurants and food\n",
    "df_b = df_b[df_b['categories'].str.contains('Restaurants|Food', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address\n",
      "attributes\n",
      "business_id\n",
      "categories\n",
      "city\n",
      "hours\n",
      "is_open\n",
      "latitude\n",
      "longitude\n",
      "name\n",
      "postal_code\n",
      "review_count\n",
      "stars\n",
      "state\n"
     ]
    }
   ],
   "source": [
    "# all columns in the business\n",
    "for col in df_b.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop some irrelevant columns**\n",
    "* As we are curiously about geo info of the restaurants, so hours, is_open, review_counts can be dropped.\n",
    "* We will need to keep the business_id to merge with the reviews.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['hours','is_open','state', 'postal_code']\n",
    "df_b = df_b.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**not all cities have enough records, so we would mainly focus on the top 2 cities with most restaurants.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toronto      6847\n",
       "Las Vegas    5621\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b.city.value_counts()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_business = df_b[df_b['city'].str.contains('Las Vegas', case=False, na=False)]\n",
    "vegas_business.to_csv(\"./vegas/vegas_business.csv\", index=False)\n",
    "\n",
    "toronto_business = df_b[df_b['city'].str.contains('Toronto', case=False, na=False)]\n",
    "toronto_business.to_csv(\"./toronto/toronto_business.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review.json is a huge file, loading all data at once will easily take all memory space on you machine, so it would be very necessary to load the data in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000000\n",
    "review = pd.read_json(review_json_path,lines = True, chunksize = size)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on vegas: 176413 out of 1,000,000 related reviews\n",
      "on toronto: 52143 out of 1,000,000 related reviews\n",
      "on vegas: 174232 out of 1,000,000 related reviews\n",
      "on toronto: 47978 out of 1,000,000 related reviews\n",
      "on vegas: 155655 out of 1,000,000 related reviews\n",
      "on toronto: 52972 out of 1,000,000 related reviews\n",
      "on vegas: 180634 out of 1,000,000 related reviews\n",
      "on toronto: 52201 out of 1,000,000 related reviews\n",
      "on vegas: 167825 out of 1,000,000 related reviews\n",
      "on toronto: 51117 out of 1,000,000 related reviews\n",
      "on vegas: 124741 out of 1,000,000 related reviews\n",
      "on toronto: 38016 out of 1,000,000 related reviews\n"
     ]
    }
   ],
   "source": [
    "vegas_chunk_list = []\n",
    "toronto_chunk_list = []\n",
    "drop_columns = ['review_id', 'user_id','funny','cool']\n",
    "for chunk_review in review:\n",
    "    chunk_review = chunk_review.drop(['review_id','funny','cool'], axis=1)\n",
    "    chunk_review = chunk_review.rename(columns={'stars': 'review_stars'})\n",
    "    vegas_chunk_merged = pd.merge(vegas_business, chunk_review, on='business_id', how='inner')\n",
    "    toronto_chunk_merged = pd.merge(toronto_business, chunk_review, on='business_id', how='inner')\n",
    "    print(f\"on vegas: {vegas_chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "    print(f\"on toronto: {toronto_chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "    vegas_chunk_list.append(vegas_chunk_merged)\n",
    "    toronto_chunk_list.append(toronto_chunk_merged)\n",
    "    \n",
    "vegas_df = pd.concat(vegas_chunk_list, join='outer',axis=0)\n",
    "toronto_df = pd.concat(toronto_chunk_list, join='outer', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegas_csv_name = \"./vegas/vegas_business+review.csv\"\n",
    "vegas_df.to_csv(vegas_csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_csv_name = \"./toronto/toronto_business+review.csv\"\n",
    "toronto_df.to_csv(toronto_csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "* So far we have finished fundamental data preprocessing for business.json and review.json, and we merged these 2 files together based on business_id of restaurants. We would make latter analysis and visualization easiler and more effective.\n",
    "* Data is useful only when we can read and store them properly. After the preprocessing, we get 4 \"clean\" data files as output (2 for Las vegas, 2 for Toronto).\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
